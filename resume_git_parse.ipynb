{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Collecting pdfminer\n",
      "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\n",
      "Requirement already satisfied: pycryptodome in c:\\conda\\lib\\site-packages (from pdfminer) (3.11.0)\n",
      "Building wheels for collected packages: pdfminer\n",
      "  Building wheel for pdfminer (setup.py): started\n",
      "  Building wheel for pdfminer (setup.py): finished with status 'done'\n",
      "  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140104 sha256=e8c735e8ce53f87dd235230fbd7590bbe6168732a083396bec652208ffcf169c\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\1c\\28\\7d\\f390b82bb0307deb63ff27a1474fd308ec68ee028cb9ab6283\n",
      "Successfully built pdfminer\n",
      "Installing collected packages: pdfminer\n",
      "Successfully installed pdfminer-20191125\n",
      "Requirement already satisfied: pdfminer.six in c:\\conda\\lib\\site-packages (20211012)\n",
      "Requirement already satisfied: cryptography in c:\\conda\\lib\\site-packages (from pdfminer.six) (3.1.1)\n",
      "Requirement already satisfied: chardet; python_version > \"3.0\" in c:\\conda\\lib\\site-packages (from pdfminer.six) (3.0.4)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\conda\\lib\\site-packages (from cryptography->pdfminer.six) (1.15.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\conda\\lib\\site-packages (from cryptography->pdfminer.six) (1.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\conda\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography->pdfminer.six) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer       \n",
    "!pip install pdfminer.six  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packaging==20.0\n",
      "  Downloading packaging-20.0-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\conda\\lib\\site-packages (from packaging==20.0) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\conda\\lib\\site-packages (from packaging==20.0) (1.15.0)\n",
      "Installing collected packages: packaging\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 18.0\n",
      "    Uninstalling packaging-18.0:\n",
      "      Successfully uninstalled packaging-18.0\n",
      "Successfully installed packaging-20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "pyresparser 1.0.6 requires jsonschema>=3.0.1, but you'll have jsonschema 2.6.0 which is incompatible.\n",
      "en-core-web-sm 2.3.1 requires spacy<2.4.0,>=2.3.0, but you'll have spacy 3.2.1 which is incompatible.\n",
      "en-core-web-lg 2.3.1 requires spacy<2.4.0,>=2.3.0, but you'll have spacy 3.2.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install packaging==20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: doc2text in c:\\conda\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: PyPDF2 in c:\\conda\\lib\\site-packages (from doc2text) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\conda\\lib\\site-packages (from doc2text) (1.5.2)\n",
      "Requirement already satisfied: mime in c:\\conda\\lib\\site-packages (from doc2text) (0.1.0)\n",
      "Requirement already satisfied: pytesseract in c:\\conda\\lib\\site-packages (from doc2text) (0.3.8)\n",
      "Requirement already satisfied: numpy in c:\\conda\\lib\\site-packages (from doc2text) (1.19.2)\n",
      "Requirement already satisfied: Pillow in c:\\conda\\lib\\site-packages (from doc2text) (8.0.1)\n",
      "Requirement already satisfied: future in c:\\conda\\lib\\site-packages (from mime->doc2text) (0.17.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install doc2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as fh:\n",
    "        # iterate over all pages of PDF document\n",
    "        for page in PDFPage.get_pages(fh, caching=True, check_extractable=True):\n",
    "            # creating a resoure manager\n",
    "            resource_manager = PDFResourceManager()\n",
    "            \n",
    "            # create a file handle\n",
    "            fake_file_handle = io.StringIO()\n",
    "            \n",
    "            # creating a text converter object\n",
    "            converter = TextConverter(\n",
    "                                resource_manager, \n",
    "                                fake_file_handle, \n",
    "                                codec='utf-8', \n",
    "                                laparams=LAParams()\n",
    "                        )\n",
    "\n",
    "            # creating a page interpreter\n",
    "            page_interpreter = PDFPageInterpreter(\n",
    "                                resource_manager, \n",
    "                                converter\n",
    "                            )\n",
    "\n",
    "            # process current page\n",
    "            page_interpreter.process_page(page)\n",
    "            \n",
    "            # extract text\n",
    "            text = fake_file_handle.getvalue()\n",
    "            yield text\n",
    "\n",
    "            # close open handles\n",
    "            converter.close()\n",
    "            fake_file_handle.close()\n",
    "\n",
    "# calling above function and extracting text\n",
    "text = ''\n",
    "for page in extract_text_from_pdf('D:/Daksh--Resume.pdf'):\n",
    "    text += ' ' + page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Version' object has no attribute 'major'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-cfd60508b4cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# load pre-trained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# initialize matcher with a vocab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     return util.load_model(\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     )\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_lang_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"blank:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# installed as package\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# path to model data directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \"\"\"\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\en_core_web_sm\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model_meta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'version'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mget_model_meta\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    850\u001b[0m     \"\"\"\n\u001b[0;32m    851\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_meta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m\"meta.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_meta\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_compatible_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"spacy_version\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[0mlower_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model_lower_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"spacy_version\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 820\u001b[1;33m             \u001b[0mlower_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_minor_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower_version\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    821\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlower_version\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m                 \u001b[0mlower_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"v\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlower_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mget_minor_version\u001b[1;34m(version)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInvalidVersion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 785\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34mf\"{v.major}.{v.minor}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Version' object has no attribute 'major'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    \n",
    "    # First name and Last name are always Proper Nouns\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    \n",
    "    matcher.add('NAME', None, pattern)\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        return span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dakshpaleria |'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_name(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_mobile_number(text):\n",
    "    phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), text)\n",
    "    \n",
    "    if phone:\n",
    "        number = ''.join(phone[0])\n",
    "        if len(number) > 10:\n",
    "            return '+' + number\n",
    "        else:\n",
    "            return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7016397736'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_mobile_number(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email(email):\n",
    "    email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", email)\n",
    "    if email:\n",
    "        try:\n",
    "            return email[0].split()[0].strip(';')\n",
    "        except IndexError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dpaleria@gmail.com'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_email(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# load pre-trained model\n",
    "noun_chunks = []\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "for chunk in nlp(text).noun_chunks:\n",
    "    noun_chunks.append(chunk.text)\n",
    "\n",
    "def extract_skills(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "\n",
    "    # removing stop words and implementing word tokenization\n",
    "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
    "    \n",
    "    # reading the csv file\n",
    "    data = pd.read_csv(\"D:/ResumeParser-master/resume_parser/resume_parser/skills.csv\") \n",
    "    \n",
    "    # extract values\n",
    "    skills = list(data.columns.values)\n",
    "    \n",
    "    skillset = []\n",
    "    \n",
    "    # check for one-grams (example: python)\n",
    "    for token in tokens:\n",
    "        if token.lower() in skills:\n",
    "            skillset.append(token)\n",
    "    \n",
    "    # check for bi-grams and tri-grams (example: machine learning)\n",
    "    for token in noun_chunks:\n",
    "        token = token.lower().strip()\n",
    "        if token in skills:\n",
    "            skillset.append(token)\n",
    "    if len(skillset)>20:\n",
    "        skillset= skillset[0:30]\n",
    "    return [i.capitalize() for i in set([i.lower() for i in skillset])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Javascript',\n",
       " 'Ios',\n",
       " 'Java',\n",
       " 'Design',\n",
       " 'Database',\n",
       " 'Sql',\n",
       " 'Php',\n",
       " 'Tensorflow',\n",
       " 'Flask',\n",
       " 'Circuits',\n",
       " 'Editing',\n",
       " 'Python',\n",
       " 'Android',\n",
       " 'R',\n",
       " 'Html',\n",
       " 'Engineering',\n",
       " 'Css',\n",
       " 'Mobile',\n",
       " 'Coding',\n",
       " 'Github',\n",
       " 'Visual',\n",
       " 'Technical',\n",
       " 'Docker',\n",
       " 'System']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_skills(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Grad all general stop words\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# Education Degrees\n",
    "EDUCATION = [\n",
    "            'BE','B.E.', 'B.E', 'BS', 'B.S', \n",
    "            'ME', 'M.E', 'M.E.', 'MS', 'M.S', \n",
    "            'BTECH', 'B.TECH', 'M.TECH', 'MTECH', \n",
    "            'SSC', 'HSC', 'CBSE', 'ICSE', 'X', 'XII'\n",
    "        ]\n",
    "\n",
    "def extract_education(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "\n",
    "    # Sentence Tokenizer\n",
    "    nlp_text = [sent.string.strip() for sent in nlp_text.sents]\n",
    "\n",
    "    edu = {}\n",
    "    # Extract education degree\n",
    "    for index, text in enumerate(nlp_text):\n",
    "        for tex in text.split():\n",
    "            # Replace all special symbols\n",
    "            tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
    "            if tex.upper() in EDUCATION and tex not in STOPWORDS:\n",
    "                edu[tex] = text + nlp_text[index + 1]\n",
    "\n",
    "    # Extract year\n",
    "    education = []\n",
    "    for key in edu.keys():\n",
    "        year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])\n",
    "        if year:\n",
    "            education.append((key, ''.join(year[0])))\n",
    "        else:\n",
    "            education.append(key)\n",
    "    return education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BE']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_education(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_sum(text):\n",
    "    print(\"NAME:\",extract_name(text))\n",
    "    print(\"PHONE No.:\",extract_mobile_number(text))\n",
    "    print(\"EMAIL:\",extract_email(text))\n",
    "    print(\"SKILLS:\",extract_skills(text))\n",
    "    print(\"EDUCATION:\",extract_education(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: dakshpaleria |\n",
      "PHONE No.: 7016397736\n",
      "EMAIL: dpaleria@gmail.com\n",
      "SKILLS: ['Javascript', 'Ios', 'Java', 'Design', 'Database', 'Sql', 'Php', 'Tensorflow', 'Flask', 'Circuits', 'Editing', 'Python', 'Android', 'R', 'Html', 'Engineering', 'Css', 'Mobile', 'Coding', 'Github', 'Visual', 'Technical', 'Docker', 'System']\n",
      "EDUCATION: ['BE']\n",
      "COLLEGE: Saurashtra University\n"
     ]
    }
   ],
   "source": [
    "resume_sum(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1= NER(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_repo(repo):\n",
    "    # repository full name\n",
    "    print(\"Full name:\", repo.full_name)\n",
    "    # repository description\n",
    "    print(\"Description:\", repo.description)\n",
    "    print(\"Date of last push:\", repo.pushed_at)\n",
    "    # programming language\n",
    "    print(\"Language:\", repo.language)\n",
    "    print(\"Number of stars:\", repo.stargazers_count)\n",
    "    print(\"-\"*50)\n",
    "    # repository content (files & directories)\n",
    "    try:\n",
    "        # repo license\n",
    "        print(\"License:\", base64.b64decode(repo.get_license().content.encode()).decode())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full name: wroetoshaw/Character-Controller\n",
      "Description: Using three js to controller-3d model with 3rd person camera\n",
      "Date of last push: 2021-11-17 16:17:28\n",
      "Language: JavaScript\n",
      "Number of stars: 0\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/DarkMedia\n",
      "Description: Dark Media is a multimedia talent management company and creative outpost for the largest creators on the internet.\n",
      "Date of last push: 2021-11-05 09:16:22\n",
      "Language: HTML\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Fancy-Scrolling-website-mp4\n",
      "Description: Fancy scrolling website using mp4 file with trigger points and end points\n",
      "Date of last push: 2021-11-05 08:41:24\n",
      "Language: HTML\n",
      "Number of stars: 2\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Fancy-scrolling-Zflip\n",
      "Description: Recreating fancy scrolling(using 200 img with 20 fps) \n",
      "Date of last push: 2021-11-04 09:50:25\n",
      "Language: JavaScript\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/galaxy-generator\n",
      "Description: generate customizable versions of milky way galaxy\n",
      "Date of last push: 2021-11-12 09:19:59\n",
      "Language: JavaScript\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Haunted-House\n",
      "Description: Haunted House 3d simulation with three js and basic shapes\n",
      "Date of last push: 2021-11-12 09:26:58\n",
      "Language: JavaScript\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/IEEE-PCS-website\n",
      "Description: unoffical website for ieee-pcs\n",
      "Date of last push: 2021-11-12 09:46:03\n",
      "Language: CSS\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Karthicc-3720\n",
      "Description: Config files for my GitHub profile.\n",
      "Date of last push: 2021-07-17 16:54:59\n",
      "Language: None\n",
      "Number of stars: 0\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Karthicc-3720.github.io\n",
      "Description: Webpage mfs\n",
      "Date of last push: 2021-08-05 18:57:32\n",
      "Language: JavaScript\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Mask-3d\n",
      "Description: Rendering a 3rd mask in a virtual environment\n",
      "Date of last push: 2021-11-29 16:58:07\n",
      "Language: JavaScript\n",
      "Number of stars: 0\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Minecraft\n",
      "Description: Minecraft on web\n",
      "Date of last push: 2021-11-29 18:56:03\n",
      "Language: JavaScript\n",
      "Number of stars: 0\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Monster-Rolodex\n",
      "Description: My first react project \n",
      "Date of last push: 2021-12-01 15:17:14\n",
      "Language: JavaScript\n",
      "Number of stars: 0\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Portfolio.github.io\n",
      "Description: WEBSITE MFS\n",
      "Date of last push: 2021-08-05 18:09:34\n",
      "Language: None\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Ride\n",
      "Description: Gsap svg tweeks\n",
      "Date of last push: 2021-11-29 18:57:16\n",
      "Language: HTML\n",
      "Number of stars: 0\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/SBSPS-Challenge-1658-AI-Recruiter---Social-and-Work-Profiling-and-Report-with-supporting-evidence\n",
      "Description: AI Recruiter which shortlists based on Social & Work Profiling, Chatbot conversation analysis and Peer-group ranking.\n",
      "Date of last push: 2021-09-08 02:19:50\n",
      "Language: None\n",
      "Number of stars: 0\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Super-Mario\n",
      "Description: The OG super mario using vanilla js \n",
      "Date of last push: 2021-09-29 16:32:11\n",
      "Language: JavaScript\n",
      "Number of stars: 2\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Sweetpablo\n",
      "Description: Landing page for the restuarent sweet pablo\n",
      "Date of last push: 2021-11-05 09:11:17\n",
      "Language: HTML\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Three-js-\n",
      "Description: Learning three js\n",
      "Date of last push: 2021-11-06 19:55:03\n",
      "Language: JavaScript\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Threejs-Custom-geometry\n",
      "Description: Custon geometry visualizer using threejs\n",
      "Date of last push: 2021-11-07 09:41:14\n",
      "Language: JavaScript\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/Todo-App\n",
      "Description: My first attempt at todo react app, has few bugs will fix in the next update/push \n",
      "Date of last push: 2021-12-02 13:39:53\n",
      "Language: JavaScript\n",
      "Number of stars: 0\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/wroetoshaw\n",
      "Description: Config files for my GitHub profile.\n",
      "Date of last push: 2021-11-03 06:32:53\n",
      "Language: None\n",
      "Number of stars: 1\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n",
      "Full name: wroetoshaw/wroetoshaw.github.io\n",
      "Description: Live Demo\n",
      "Date of last push: 2021-11-17 17:22:52\n",
      "Language: JavaScript\n",
      "Number of stars: 0\n",
      "--------------------------------------------------\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from github import Github\n",
    "from pprint import pprint\n",
    "\n",
    "# Github username\n",
    "username = \"wroetoshaw\"\n",
    "# pygithub object\n",
    "g = Github()\n",
    "# get that user by username\n",
    "user = g.get_user(username)\n",
    "for repo in user.get_repos():\n",
    "    print_repo(repo)\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyGithub\n",
      "  Downloading PyGithub-1.55-py3-none-any.whl (291 kB)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in c:\\conda\\lib\\site-packages (from PyGithub) (1.4.0)\n",
      "Collecting deprecated\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests>=2.14.0 in c:\\conda\\lib\\site-packages (from PyGithub) (2.24.0)\n",
      "Collecting pyjwt>=2.0\n",
      "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: cffi>=1.4.1 in c:\\conda\\lib\\site-packages (from pynacl>=1.4.0->PyGithub) (1.14.3)\n",
      "Requirement already satisfied: six in c:\\conda\\lib\\site-packages (from pynacl>=1.4.0->PyGithub) (1.15.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\conda\\lib\\site-packages (from deprecated->PyGithub) (1.12.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\conda\\lib\\site-packages (from requests>=2.14.0->PyGithub) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\conda\\lib\\site-packages (from requests>=2.14.0->PyGithub) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\conda\\lib\\site-packages (from requests>=2.14.0->PyGithub) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\conda\\lib\\site-packages (from requests>=2.14.0->PyGithub) (2.10)\n",
      "Requirement already satisfied: pycparser in c:\\conda\\lib\\site-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.20)\n",
      "Installing collected packages: deprecated, pyjwt, PyGithub\n",
      "Successfully installed PyGithub-1.55 deprecated-1.2.13 pyjwt-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PyGithub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scrape_linkedin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-f859199d55c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscrape_linkedin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProfileScraper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mProfileScraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscraper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'austinoboyle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scrape_linkedin'"
     ]
    }
   ],
   "source": [
    "from scrape_linkedin import ProfileScraper\n",
    "\n",
    "with ProfileScraper() as scraper:\n",
    "    profile = scraper.scrape(user='austinoboyle')\n",
    "print(profile.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/austinoboyle/scrape-linkedin-selenium.git\n",
      "  Cloning git://github.com/austinoboyle/scrape-linkedin-selenium.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-6c5n8ys6\n",
      "Requirement already satisfied: beautifulsoup4>=4.6.0 in c:\\conda\\lib\\site-packages (from scrape-linkedin==0.8.0) (4.9.3)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
      "Requirement already satisfied: click in c:\\conda\\lib\\site-packages (from scrape-linkedin==0.8.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\conda\\lib\\site-packages (from scrape-linkedin==0.8.0) (0.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\conda\\lib\\site-packages (from beautifulsoup4>=4.6.0->scrape-linkedin==0.8.0) (2.0.1)\n",
      "Collecting urllib3[secure]~=1.26\n",
      "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
      "Requirement already satisfied: idna>=2.0.0; extra == \"secure\" in c:\\conda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium->scrape-linkedin==0.8.0) (2.10)\n",
      "Requirement already satisfied: cryptography>=1.3.4; extra == \"secure\" in c:\\conda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium->scrape-linkedin==0.8.0) (3.1.1)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14; extra == \"secure\" in c:\\conda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium->scrape-linkedin==0.8.0) (19.1.0)\n",
      "Requirement already satisfied: certifi; extra == \"secure\" in c:\\conda\\lib\\site-packages (from urllib3[secure]~=1.26->selenium->scrape-linkedin==0.8.0) (2020.6.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: async-generator>=1.10 in c:\\conda\\lib\\site-packages (from trio-websocket~=0.9->selenium->scrape-linkedin==0.8.0) (1.10)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: cffi>=1.14; os_name == \"nt\" and implementation_name != \"pypy\" in c:\\conda\\lib\\site-packages (from trio~=0.17->selenium->scrape-linkedin==0.8.0) (1.14.3)\n",
      "Requirement already satisfied: sortedcontainers in c:\\conda\\lib\\site-packages (from trio~=0.17->selenium->scrape-linkedin==0.8.0) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\conda\\lib\\site-packages (from trio~=0.17->selenium->scrape-linkedin==0.8.0) (20.3.0)\n",
      "Requirement already satisfied: sniffio in c:\\conda\\lib\\site-packages (from trio~=0.17->selenium->scrape-linkedin==0.8.0) (1.2.0)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\conda\\lib\\site-packages (from cryptography>=1.3.4; extra == \"secure\"->urllib3[secure]~=1.26->selenium->scrape-linkedin==0.8.0) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\conda\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->scrape-linkedin==0.8.0) (0.9.0)\n",
      "Requirement already satisfied: pycparser in c:\\conda\\lib\\site-packages (from cffi>=1.14; os_name == \"nt\" and implementation_name != \"pypy\"->trio~=0.17->selenium->scrape-linkedin==0.8.0) (2.20)\n",
      "Building wheels for collected packages: scrape-linkedin, bs4\n",
      "  Building wheel for scrape-linkedin (setup.py): started\n",
      "  Building wheel for scrape-linkedin (setup.py): finished with status 'done'\n",
      "  Created wheel for scrape-linkedin: filename=scrape_linkedin-0.8.0-py2.py3-none-any.whl size=23875 sha256=1f150ae0a229ae67c9c91cad8f30b909e1e397f4af581dd17f853eed30b3d841\n",
      "  Stored in directory: C:\\Users\\user\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-w_de2w2z\\wheels\\db\\38\\14\\026a904c87e4e4606cb1111c95b5eb6c4e0aa922c2ac9e0d7c\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1277 sha256=89fa9a344a78de10937dacffbaab79efdbe4d1145f6d5d18779ef45a63a6b0ea\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built scrape-linkedin bs4\n",
      "Installing collected packages: bs4, urllib3, wsproto, outcome, trio, trio-websocket, selenium, scrape-linkedin\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\n",
      "Successfully installed bs4-0.0.1 outcome-1.1.0 scrape-linkedin-0.8.0 selenium-4.1.0 trio-0.19.0 trio-websocket-0.9.2 urllib3-1.26.7 wsproto-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "conda 4.11.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\n",
      "requests 2.24.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.7 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/austinoboyle/scrape-linkedin-selenium.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
